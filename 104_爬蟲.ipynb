{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1頁已爬取完成\n",
      "第2頁已爬取完成\n",
      "第3頁已爬取完成\n",
      "第4頁已爬取完成\n",
      "第5頁已爬取完成\n",
      "第6頁已爬取完成\n",
      "第7頁已爬取完成\n",
      "第8頁已爬取完成\n",
      "第9頁已爬取完成\n",
      "第10頁已爬取完成\n",
      "第11頁已爬取完成\n",
      "第12頁已爬取完成\n",
      "第13頁已爬取完成\n",
      "第14頁已爬取完成\n",
      "第15頁已爬取完成\n",
      "第16頁已爬取完成\n",
      "第17頁已爬取完成\n",
      "第18頁已爬取完成\n",
      "第19頁已爬取完成\n",
      "第20頁已爬取完成\n",
      "第21頁已爬取完成\n",
      "第22頁已爬取完成\n",
      "第23頁已爬取完成\n",
      "第24頁已爬取完成\n",
      "第25頁已爬取完成\n",
      "第26頁已爬取完成\n",
      "第27頁已爬取完成\n",
      "第28頁已爬取完成\n",
      "第29頁已爬取完成\n",
      "第30頁已爬取完成\n",
      "第31頁已爬取完成\n",
      "第32頁已爬取完成\n",
      "第33頁已爬取完成\n",
      "第34頁已爬取完成\n",
      "第35頁已爬取完成\n",
      "第36頁已爬取完成\n",
      "第37頁已爬取完成\n",
      "第38頁已爬取完成\n",
      "第39頁已爬取完成\n",
      "第40頁已爬取完成\n",
      "第41頁已爬取完成\n",
      "第42頁已爬取完成\n",
      "第43頁已爬取完成\n",
      "第44頁已爬取完成\n",
      "第45頁已爬取完成\n",
      "第46頁已爬取完成\n",
      "第47頁已爬取完成\n",
      "第48頁已爬取完成\n",
      "第49頁已爬取完成\n",
      "第50頁已爬取完成\n",
      "第51頁已爬取完成\n",
      "第52頁已爬取完成\n",
      "第53頁已爬取完成\n",
      "第54頁已爬取完成\n",
      "第55頁已爬取完成\n",
      "第56頁已爬取完成\n",
      "第57頁已爬取完成\n",
      "第58頁已爬取完成\n",
      "第59頁已爬取完成\n",
      "第60頁已爬取完成\n",
      "第61頁已爬取完成\n",
      "第62頁已爬取完成\n",
      "第63頁已爬取完成\n",
      "第64頁已爬取完成\n",
      "第65頁已爬取完成\n",
      "第66頁已爬取完成\n",
      "第67頁已爬取完成\n",
      "第68頁已爬取完成\n",
      "第69頁已爬取完成\n",
      "第70頁已爬取完成\n",
      "第71頁已爬取完成\n",
      "第72頁已爬取完成\n",
      "第73頁已爬取完成\n",
      "第74頁已爬取完成\n",
      "第75頁已爬取完成\n",
      "第76頁已爬取完成\n",
      "第77頁已爬取完成\n",
      "第78頁已爬取完成\n",
      "第79頁已爬取完成\n",
      "第80頁已爬取完成\n",
      "第81頁已爬取完成\n",
      "第82頁已爬取完成\n",
      "第83頁已爬取完成\n",
      "第84頁已爬取完成\n",
      "第85頁已爬取完成\n",
      "第86頁已爬取完成\n",
      "第87頁已爬取完成\n",
      "第88頁已爬取完成\n",
      "第89頁已爬取完成\n",
      "第90頁已爬取完成\n",
      "第91頁已爬取完成\n",
      "第92頁已爬取完成\n",
      "第93頁已爬取完成\n",
      "第94頁已爬取完成\n",
      "第95頁已爬取完成\n",
      "第96頁已爬取完成\n",
      "第97頁已爬取完成\n",
      "第98頁已爬取完成\n",
      "第99頁已爬取完成\n",
      "第100頁已爬取完成\n",
      "第101頁已爬取完成\n",
      "第102頁已爬取完成\n",
      "第103頁已爬取完成\n",
      "第104頁已爬取完成\n",
      "第105頁已爬取完成\n",
      "第106頁已爬取完成\n",
      "第107頁已爬取完成\n",
      "第108頁已爬取完成\n",
      "第109頁已爬取完成\n",
      "第110頁已爬取完成\n",
      "第111頁已爬取完成\n",
      "第112頁已爬取完成\n",
      "第113頁已爬取完成\n",
      "第114頁已爬取完成\n",
      "第115頁已爬取完成\n",
      "第116頁已爬取完成\n",
      "第117頁已爬取完成\n",
      "第118頁已爬取完成\n",
      "第119頁已爬取完成\n",
      "第120頁已爬取完成\n",
      "已爬取完成\n"
     ]
    }
   ],
   "source": [
    "'''整合完成'''\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "'''關鍵字搜尋'''\n",
    "search = '資料工程師' \n",
    "\n",
    "'''頁數起始值'''\n",
    "page = 1\n",
    "\n",
    "'''先建立一個有字串的list，以便進入if迴圈'''\n",
    "list=['a']\n",
    "\n",
    "'''建立dataframe的headers'''\n",
    "columns = [\n",
    "    '職稱', '公司', '職務類別', '工作內容', '薪資', '公司區域', '詳細地址', '相對位置', '上班時段', '休假制度', '工作經歷', '學歷要求', '語文條件', '語文能力', '擅長工具', '其他條件', '法定福利', '其他福利', '特殊福利'\n",
    "                ]\n",
    "\n",
    "df = pd.DataFrame(columns = columns)\n",
    "\n",
    "while True:   \n",
    "    if len(list) != 0:\n",
    "        url = 'https://www.104.com.tw/jobs/search/?ro=0&keyword='+ search +'&expansionType=area%2Cspec%2Ccom%2Cjob%2Cwf%2Cwktm&order=12&asc=0&page='+ str(page) +'&mode=s&jobsource=2018indexpoc'\n",
    "\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36'\n",
    "        }\n",
    "\n",
    "        res = requests.get(url, headers=headers)\n",
    "        html = res.text\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        content = soup.select('div#js-job-content')[0]\n",
    "        list = content.select('article[class=\"b-block--top-bord job-list-item b-clearfix js-job-item\"]')\n",
    "#         print(f'\\npage:{page}')\n",
    "        \n",
    "        for i in list:\n",
    "            b_tit = i.select('h2[class=\"b-tit\"]')[0]\n",
    "            for link in b_tit.select('a'):\n",
    "                link_url = link.get('href')\n",
    "#                 print(link_url)\n",
    "                headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36'\n",
    "                }\n",
    "\n",
    "                res = requests.get(str('http:')+link_url, headers=headers)\n",
    "                html = res.text\n",
    "\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                key = link_url[21:26]\n",
    "#                 print(key)\n",
    "                url = 'https://www.104.com.tw/job/ajax/content/'+str(key)\n",
    "                headers = {\n",
    "                'Referer': 'https://www.104.com.tw/job/'+str(key)+'?jobsource=jolist_d_relevance',\n",
    "                'Content-Type': 'application/json;charset=utf-8',\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36'\n",
    "                }\n",
    "\n",
    "                res = requests.get(url, headers=headers)\n",
    "                \n",
    "                #宣告一個變數來接住res.text\n",
    "                jsonData = json.loads(res.text) #轉換成一個list的json字串 \n",
    "                '''職稱'''\n",
    "                jobName = jsonData[\"data\"][\"header\"][\"jobName\"]\n",
    "                \n",
    "                '''公司名稱'''\n",
    "                comName = jsonData[\"data\"][\"header\"][\"custName\"] \n",
    "                \n",
    "                '''職務類別'''\n",
    "                jC = jsonData[\"data\"][\"jobDetail\"][\"jobCategory\"]\n",
    "                if jC == []:\n",
    "                    jobCategory = '不拘'\n",
    "                else:\n",
    "                    j_C = jC[0]\n",
    "                    jCC = [j_C['description'] for j in jC]\n",
    "                    jobCategory = \",\".join(jCC) \n",
    "                \n",
    "                \n",
    "                '''工作內容'''\n",
    "                jd = jsonData[\"data\"][\"jobDetail\"][\"jobDescription\"] \n",
    "                j = re.sub(r'[=-]', '*', jd)\n",
    "                jobDetail = j.replace(\"\\n\",\"\")\n",
    "                \n",
    "                '''薪資'''\n",
    "                salary = jsonData[\"data\"][\"jobDetail\"][\"salary\"]\n",
    "                \n",
    "                '''公司區域'''\n",
    "                addressRegion = jsonData[\"data\"][\"jobDetail\"][\"addressRegion\"]\n",
    "                \n",
    "                '''詳細地址'''\n",
    "                aD = jsonData[\"data\"][\"jobDetail\"][\"addressDetail\"]\n",
    "                addressDetail = '未填寫' if aD == \"\" else jsonData[\"data\"][\"jobDetail\"][\"addressDetail\"]\n",
    "\n",
    "                '''相對位置'''\n",
    "                lm = jsonData[\"data\"][\"jobDetail\"][\"landmark\"]\n",
    "                landmark = '未填寫' if lm == \"\" else jsonData[\"data\"][\"jobDetail\"][\"landmark\"]\n",
    "\n",
    "                '''上班時段'''\n",
    "                wP = jsonData[\"data\"][\"jobDetail\"][\"workPeriod\"] \n",
    "                workPeriod = '未填寫' if wP == \"\" else jsonData[\"data\"][\"jobDetail\"][\"workPeriod\"]\n",
    "\n",
    "                '''休假制度'''\n",
    "                vP = jsonData[\"data\"][\"jobDetail\"][\"vacationPolicy\"]\n",
    "                vacPolicy = '未填寫' if vP == \"\" else jsonData[\"data\"][\"jobDetail\"][\"vacationPolicy\"] \n",
    "                \n",
    "                '''工作經驗'''\n",
    "                workExp = jsonData[\"data\"][\"condition\"][\"workExp\"]\n",
    "                \n",
    "                '''教育程度'''\n",
    "                edu = jsonData[\"data\"][\"condition\"][\"edu\"]\n",
    "                \n",
    "                \n",
    "                '''語言'''\n",
    "                lan = jsonData[\"data\"][\"condition\"][\"language\"]\n",
    "                if lan == []:\n",
    "                    language = '不拘'\n",
    "                    lanAbility = '不拘'\n",
    "                else:\n",
    "                    language = jsonData[\"data\"][\"condition\"][\"language\"][0][\"language\"] \n",
    "                    lanAbility = jsonData[\"data\"][\"condition\"][\"language\"][0][\"ability\"] #語言能力\n",
    "\n",
    "                '''擅長工具'''\n",
    "                s = jsonData[\"data\"][\"condition\"][\"specialty\"]\n",
    "                l = []\n",
    "                if s == []:\n",
    "                    spe = '不拘'\n",
    "                else:\n",
    "                #     ss = [i['description'] for i in s]\n",
    "                #     spe = \",\".join(ss) \n",
    "                    for i in s:\n",
    "                        ss = i['description']\n",
    "                        if ss == None:\n",
    "                            pass\n",
    "                        else:\n",
    "                            l.append(ss)\n",
    "                            spe = \",\".join(l) \n",
    "\n",
    "                '''其他條件'''\n",
    "                o = jsonData[\"data\"][\"condition\"][\"other\"] \n",
    "                if o == \"\" or o == \" \" :\n",
    "                    othCon = '不拘'\n",
    "                else:    \n",
    "                    ot = re.sub(r'[=-]', '*', o)\n",
    "                    othCon = ot.replace(\"\\n\",\"\")\n",
    "\n",
    "                '''法定福利'''\n",
    "                wl = jsonData[\"data\"][\"welfare\"][\"legalTag\"]\n",
    "                welfare_legal = '未填寫' if wl == [] else \",\".join(wl)\n",
    " \n",
    "\n",
    "                '''其他福利'''\n",
    "                ow = jsonData[\"data\"][\"welfare\"][\"tag\"]\n",
    "                welfare_oth = '未填寫' if ow == [] else \",\".join(ow)\n",
    "\n",
    "                '''自訂福利'''\n",
    "                w = jsonData[\"data\"][\"welfare\"][\"welfare\"]\n",
    "                if w == \"\" or w == \" \" :\n",
    "                    welfare = '未填寫'\n",
    "                else:    \n",
    "                    wf = re.sub(r'[=-]', '*', w)\n",
    "                    welfare = wf.replace(\"\\n\",\"\")\n",
    "\n",
    "                data = [\n",
    "                    [jobName, comName, jobCategory, jobDetail, salary, addressRegion, addressDetail, landmark, workPeriod, vacPolicy, workExp, edu, language, lanAbility, spe, othCon, welfare_legal, welfare_oth, welfare]\n",
    "                ]\n",
    "                df_crawler = pd.DataFrame(data=data,columns=columns)\n",
    "                df = df_crawler.append(df)\n",
    "        print(f'第{page}頁已爬取完成')\n",
    "        page+=1\n",
    "\n",
    "    if len(list) == 0:\n",
    "        break  \n",
    "        \n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.sort_index(ascending=False)\n",
    "df = df.reset_index(drop=True)\n",
    "df.index = df.index + 1\n",
    "df.to_csv('C:\\\\Users\\\\Drumstick\\\\Desktop\\\\104_crawler.csv', index=1, encoding='utf-8-sig', header=1)\n",
    "print('已爬取完成')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
